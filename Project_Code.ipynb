{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/moa2020\n"
     ]
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln -s /scratch/work/courses/AppliedGenomicsSec3/groups/group5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrwxrwxrwx. 1 moa2020 moa2020 55 Apr 17 12:26 group5 -> /scratch/work/courses/AppliedGenomicsSec3/groups/group5\n"
     ]
    }
   ],
   "source": [
    "ls -l group5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd group5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importation From NCBI GEO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the fastq files for the 12 samples to be analyzed. This is done using a script which contains an array of numbers and the fasterq dump command from SRA tools. The option \"split\" is used here because the reads are paired end reads which need to be split in two before trimming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch import.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --time=5:00:00\n",
      "#SBATCH --mem=16GB\n",
      "#SBATCH --array=0-11\n",
      "#SBATCH --job-name=import\n",
      "#SBATCH --output=import_slurm_%j.out\n",
      "\n",
      "##########\n",
      "\n",
      "# array contains list of numbers corresponsing to the last figures in SRR numbers of samples\n",
      "# split-3 opition to split spots into biological reads.\n",
      "\n",
      "#########\n",
      "\n",
      "module load sra-tools/2.10.9\n",
      "module load fastqc/0.11.9\n",
      "\n",
      "# Creating the array for the SRR numbers\n",
      "file_arr=(76 77 78 79 80 81 82 83 84 85 86 87)\n",
      "echo ${file_arr[1]}\n",
      "\n",
      "# To get fastq files and change permissions\n",
      "fasterq-dump SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]} --split-3\n",
      "chmod 777 *fastq\n",
      "\n",
      "# To perform fastqc analysis\n",
      "fastqc SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_1.fastq\n",
      "fastqc SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_2.fastq"
     ]
    }
   ],
   "source": [
    "cat import.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 32457027\n"
     ]
    }
   ],
   "source": [
    "sbatch import.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.3G Apr 17 13:21 SRR9079176_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.8G Apr 17 13:21 SRR9079176_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.7G Apr 17 13:20 SRR9079177_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.8G Apr 17 13:20 SRR9079177_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.0G Apr 17 13:20 SRR9079178_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.4G Apr 17 13:20 SRR9079178_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.8G Apr 17 13:20 SRR9079179_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.0G Apr 17 13:20 SRR9079179_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.6G Apr 17 13:20 SRR9079180_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.7G Apr 17 13:20 SRR9079180_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.0G Apr 17 13:20 SRR9079181_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.3G Apr 17 13:20 SRR9079181_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.9G Apr 17 13:20 SRR9079182_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.1G Apr 17 13:20 SRR9079182_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.0G Apr 17 13:20 SRR9079183_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.3G Apr 17 13:20 SRR9079183_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.6G Apr 17 13:20 SRR9079184_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.6G Apr 17 13:20 SRR9079184_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.9G Apr 17 13:20 SRR9079185_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.2G Apr 17 13:20 SRR9079185_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 2.2G Apr 17 13:21 SRR9079186_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.7G Apr 17 13:21 SRR9079186_2.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 1.9G Apr 17 13:20 SRR9079187_1.fastq\n",
      "-rwxrwxrwx+ 1 moa2020 moa2020 3.2G Apr 17 13:20 SRR9079187_2.fastq\n"
     ]
    }
   ],
   "source": [
    "ls -lh *fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a directory for all SLURM output and fastqc analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir all_slurm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir fastqc_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *out import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv import all_slurm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *html fastqc_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *zip fastqc_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection of the fastqc analysis results, none of the reads have sequences of poor quality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming Low-Quality Bases using Trimmomatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although none of the reads reported sequences of poor-quality, we will trim out low-quality bases as an extra quality control step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch trim.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --time=5:00:00\n",
      "#SBATCH --mem=16GB\n",
      "#SBATCH --array=0-11\n",
      "#SBATCH --job-name=trim\n",
      "#SBATCH --output=trim_slurm_%j.out\n",
      "\n",
      "##########\n",
      "\n",
      "# SBATCH Code accepts #two PE (Paired End)# fastq file.\n",
      "# Output will  be 4 other fastq file with forward/ reverse, paired/unpaired\n",
      "# From fastqc analysis, the following sequence lengths were observed for read 1: 14 nucleotides and read 2: 51 nucleotides\n",
      "# Given the length of read 1, the minimum length for trimming was set to 10 nucleotides.\n",
      "#########\n",
      "\n",
      "module purge\n",
      "module load trimmomatic/0.39\n",
      "\n",
      "# Creating the array for the SRR numbers\n",
      "file_arr=(76 77 78 79 80 81 82 83 84 85 86 87)\n",
      "\n",
      "# Call Trimmomatic module for trim\n",
      "java -jar $TRIMMOMATIC_JAR PE -threads 8 -phred33 SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_1.fastq SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_2.fastq \\\n",
      "SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_forward_paired.fastq SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_forward_unpaired.fastq \\\n",
      "SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_reverse_paired.fastq SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_reverse_unpaired.fastq \\\n",
      "ILLUMINACLIP:$TRIMMOMATIC_ROOT/adapters/TruSeq3-PE.fa:2:30:10 \\\n",
      "LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:10\n"
     ]
    }
   ],
   "source": [
    "cat trim.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 32795050\n"
     ]
    }
   ],
   "source": [
    "sbatch trim.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a directory for all trim SLURM output and adding them to existing SLURM outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *out trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv trim all_slurm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Alignment Using Hisat-2\n",
    "The Human genome was obtained from https://www.ncbi.nlm.nih.gov/genome/guide/human/. The file was unzipped and an index was created. The trimmed paired reads were aligned to the reference genome to create SAM files using the Hisat-2 aligner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip GRCh38_latest_genomic.fna.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch align.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --time=5:00:00\n",
      "#SBATCH --mem=16GB\n",
      "#SBATCH --array=0-11\n",
      "#SBATCH --job-name=alignment\n",
      "#SBATCH --output=alignment_slurm_%j.out\n",
      "\n",
      "##########\n",
      "\n",
      "# SBATCH Code accepts two paired end files: forward (1) and reverse (2)\n",
      "# $1 = reference genome: GRCh38.fa\n",
      "# $2 = index prefix: human\n",
      "\n",
      "#########\n",
      "\n",
      "module purge\n",
      "module load hisat2/2.2.1\n",
      "\n",
      "# To build the reference genome index\n",
      "hisat2-build $1 $2_genome\n",
      "\n",
      "# Creating the array for the SRR numbers\n",
      "file_arr=(76 77 78 79 80 81 82 83 84 85 86 87)\n",
      "\n",
      "# To run alignment on the trimmed file\n",
      "hisat2 -x $2_genome -1 SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_forward_paired.fastq -2 SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_reverse_paired.fastq \\\n",
      "-S SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}.sam -p 8\n"
     ]
    }
   ],
   "source": [
    "cat align.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 32850243\n"
     ]
    }
   ],
   "source": [
    "sbatch align.sh GRCh38_latest_genomic.fna h_sapiens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the output of the alignment. \n",
    "The flagstat command in the Samtools module will be used to inspect the quality of the alignment. If the percentage of mapped reads is less than 65% (as specified in our proposal), the alignent will be considered a failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lh *sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch inspect_alignment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --time=5:00:00\n",
      "#SBATCH --mem=16GB\n",
      "#SBATCH --array=0-11\n",
      "#SBATCH --job-name=inspection\n",
      "#SBATCH --output=inspection_slurm_%j.out\n",
      "\n",
      "##########\n",
      "\n",
      "# SBATCH Code analyzes the quality of the alignment performed.\n",
      "\n",
      "#########\n",
      "\n",
      "module purge\n",
      "module load samtools/intel/1.14\n",
      "\n",
      "# Creating the array\n",
      "file_arr=(*sam)\n",
      "\n",
      "# To inspect the output of the alignment\n",
      "samtools flagstat ${file_arr[$SLURM_ARRAY_TASK_ID]}\n"
     ]
    }
   ],
   "source": [
    "cat inspect_alignment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 32859433\n"
     ]
    }
   ],
   "source": [
    "sbatch inspect_alignment.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection of the SAM files obtained from the sequence alignment using hisat-2, several SAM files reported 0 mapping and the highest mapping percent reported was 53.72%. Hence, the sequence alignment was considered a failure. We decided to use a different splice-aware sequence aligner, STAR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Alignment Using STAR\n",
    "The Human (GRCh38) reference genome and genome annotation file were obtained from https://www.ncbi.nlm.nih.gov/genome/guide/human/. The file was unzipped and an index was created. The trimmed paired reads were aligned to the reference genome to create SAM files using the STAR aligner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip GRCh38_latest_genomic.gff.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch star_alignment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create the directory where the reference genome will be stored\n",
    "mkdir human_genome_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=16\n",
      "#SBATCH --time=24:00:00\n",
      "#SBATCH --mem=48GB\n",
      "#SBATCH --array=0-11\n",
      "#SBATCH --job-name=Star_align\n",
      "#SBATCH --output=star_alignment_slurm_%j.out\n",
      "\n",
      "##########\n",
      "\n",
      "# SBATCH Code accepts two paired end files: forward (1) and reverse (2)\n",
      "\n",
      "# BUILDING THE REFERENCE GENOME\n",
      "# --runThread: Number of threads (processors) for mapping reads to a genome\n",
      "# --runmode: run mode for STAR. genomeGenerate mode builds genome index\n",
      "# $1 = path to the directory (genomeDir) where the reference genome index will be stored: human_genome_index\n",
      "# $2 = reference genome file in FASTA format (genomeFastaFiles): GRCh38_latest_genomic.fna\n",
      "# $3 = GTF file for gene annotation (sjdbGTFfile): GRCh38_latest_genomic.gff\n",
      "# --sjdbGTFtagExonParentTranscript: for defining the parent-child relationship when using GFF instead of GTF file\n",
      "# --sjdbOverhang: length of reads around the splice junctions. The ideal values should be max(read length)-1: 50\n",
      "\n",
      "# MAPPING THE READS TO THE GENOME\n",
      "# --readFilesIn: read files for mapping to the genome\n",
      "# --outSAMtype: output coordinate sorted BAM file \n",
      "# --outFileNamePrefix: provide output file prefix name\n",
      "# --outputSAMunmapped: output unmapped reads from the main SAM file in SAM format.\n",
      "\n",
      "#########\n",
      "\n",
      "# Setting up the module environment\n",
      "module purge\n",
      "module load gcc/10.2.0 \n",
      "module load star/intel/2.7.6a\n",
      "\n",
      "# To build the reference genome index using the GFF3 file\n",
      "STAR --runThreadN 12 \\\n",
      "--runMode genomeGenerate \\\n",
      "--genomeDir $1 \\\n",
      "--genomeFastaFiles $2 \\\n",
      "--sjdbGTFfile $3 \\\n",
      "--sjdbGTFtagExonParentTranscript Parent \\\n",
      "--sjdbOverhang 50\n",
      "\n",
      "# Creating the array for the SRR numbers\n",
      "file_arr=(76 77 78 79 80 81 82 83 84 85 86 87)\n",
      "\n",
      "# To map the trimmed paired end file to the genome\n",
      "STAR --runThreadN 12 \\\n",
      "--readFilesIn SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_forward_paired.fastq SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_reverse_paired.fastq \\\n",
      "--genomeDir $1 \\\n",
      "--outSAMtype BAM SortedByCoordinate \\\n",
      "--outFileNamePrefix SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}  \\\n",
      "--outSAMunmapped Within\n"
     ]
    }
   ],
   "source": [
    "cat star_alignment.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 32862501\n"
     ]
    }
   ],
   "source": [
    "sbatch star_alignment.sh human_genome_index GRCh38_latest_genomic.fna GRCh38_latest_genomic.gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          32868955        cs ood-jupy  moa2020  R    1:12:35      1 cs116\n",
      "        32862501_0        cs Star_ali  moa2020  R    9:17:53      1 cs146\n",
      "        32862501_1        cs Star_ali  moa2020  R    9:17:53      1 cs155\n",
      "        32862501_2        cs Star_ali  moa2020  R    9:17:53      1 cs194\n",
      "        32862501_3        cs Star_ali  moa2020  R    9:17:53      1 cs292\n",
      "        32862501_4        cs Star_ali  moa2020  R    9:17:53      1 cs377\n",
      "        32862501_5        cs Star_ali  moa2020  R    9:17:53      1 cs379\n",
      "        32862501_6        cs Star_ali  moa2020  R    9:17:53      1 cs398\n",
      "        32862501_7        cs Star_ali  moa2020  R    9:17:53      1 cs403\n",
      "        32862501_8        cs Star_ali  moa2020  R    9:17:53      1 cs409\n",
      "        32862501_9        cs Star_ali  moa2020  R    9:17:53      1 cs456\n",
      "       32862501_11        cs Star_ali  moa2020  R    9:17:53      1 cs075\n"
     ]
    }
   ],
   "source": [
    "squeue -u moa2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 32862508\n",
      "Array Job ID: 32862501_5\n",
      "Cluster: greene\n",
      "User/Group: moa2020/moa2020\n",
      "State: RUNNING\n",
      "Nodes: 1\n",
      "Cores per node: 16\n",
      "CPU Utilized: 00:00:00\n",
      "CPU Efficiency: 0.00% of 5-20:17:36 core-walltime\n",
      "Job Wall-clock time: 08:46:06\n",
      "Memory Utilized: 0.00 MB (estimated maximum)\n",
      "Memory Efficiency: 0.00% of 48.00 GB (48.00 GB/node)\n",
      "WARNING: Efficiency statistics may be misleading for RUNNING jobs.\n"
     ]
    }
   ],
   "source": [
    "seff 32862501_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the trimmed fastq files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "touch inspect_trimming.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "\n",
      "#SBATCH --cpus-per-task=8\n",
      "#SBATCH --time=5:00:00\n",
      "#SBATCH --mem=16GB\n",
      "#SBATCH --array=0-11\n",
      "#SBATCH --job-name=inspect_trimming\n",
      "#SBATCH --output=inspect_trimming_fastq_slurm_%j.out\n",
      "\n",
      "##########\n",
      "\n",
      "# This script performs fastqc analysis on the trimmed paired fastq files.\n",
      "\n",
      "#########\n",
      "\n",
      "module load fastqc/0.11.9\n",
      "\n",
      "# Creating the array for the SRR numbers\n",
      "file_arr=(76 77 78 79 80 81 82 83 84 85 86 87)\n",
      "echo ${file_arr[1]}\n",
      "\n",
      "# To perform fastqc analysis\n",
      "fastqc SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_forward_paired.fastq\n",
      "fastqc SRR90791${file_arr[$SLURM_ARRAY_TASK_ID]}_reverse_paired.fastq\n"
     ]
    }
   ],
   "source": [
    "cat inspect_trimming.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 32869789\n"
     ]
    }
   ],
   "source": [
    "sbatch inspect_trimming.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "          32868955        cs ood-jupy  moa2020  R      30:42      1 cs116\n",
      "        32862501_0        cs Star_ali  moa2020  R    8:36:00      1 cs146\n",
      "        32862501_1        cs Star_ali  moa2020  R    8:36:00      1 cs155\n",
      "        32862501_2        cs Star_ali  moa2020  R    8:36:00      1 cs194\n",
      "        32862501_3        cs Star_ali  moa2020  R    8:36:00      1 cs292\n",
      "        32862501_4        cs Star_ali  moa2020  R    8:36:00      1 cs377\n",
      "        32862501_5        cs Star_ali  moa2020  R    8:36:00      1 cs379\n",
      "        32862501_6        cs Star_ali  moa2020  R    8:36:00      1 cs398\n",
      "        32862501_7        cs Star_ali  moa2020  R    8:36:00      1 cs403\n",
      "        32862501_8        cs Star_ali  moa2020  R    8:36:00      1 cs409\n",
      "        32862501_9        cs Star_ali  moa2020  R    8:36:00      1 cs456\n",
      "       32862501_11        cs Star_ali  moa2020  R    8:36:00      1 cs075\n"
     ]
    }
   ],
   "source": [
    "squeue -u moa2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir trimmed_fastqc_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon our inspection of the fastqc analysis results for our paired trimmed files, there were no sequences flagged for poor quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a directory for all align SLURM output and adding them to existing SLURM outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir star_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *out star_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a directory for all Fastq files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir trimmed_fastq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *paired.fastq trimmed_fastq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir raw_fastq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv *fastq raw_fastq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir all_fastq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv trimmed_fastq_files all_fastq_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv raw_fastq_files all_fastq_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Read Count Matrix.\n",
    "htseqcount is used to build a count matrix. The matrix contains information specifically about the gene counts as \"exon\" is specified as the feature to count. The gff3 features file was obtained from https://www.ncbi.nlm.nih.gov/genome/guide/human/. The GFF3 file will be unzipped and used to build the count matrix in addition to the sorted and indexed BAM file. We ensured to use a reference genome file and features file from the same source to prevent errors due to non-compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step: Importing the Count Matrix File.\n",
    "We obtained the count matrix file from https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE131391Merging. The matrix file is unzipped and will be read into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip GSE131391_count_matrix.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a directory for our R files\n",
    "mkdir Final_Project_grp5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
